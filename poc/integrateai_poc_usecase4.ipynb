{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8e5544-a80e-4e0a-84ec-0a3b32d6e9f7",
   "metadata": {},
   "source": [
    "# PoC Use Case 4\n",
    "## New Peril Score Disparity (Dislocation) Analysis\n",
    "### Powered by integrate.ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087f624-4961-4956-88e1-721c4b3449d1",
   "metadata": {},
   "source": [
    "# **integrate.ai**\n",
    "\n",
    "integrate.ai's platform, allows its users to collaborate and to perform secure and privacy preserving analytics and machine learning jobs. In this guide, we show case some of the key functionality of integrate.ai's platform to demonstrate\n",
    "\n",
    "1. integrate.ai's solution for Match Rate Analysis, Exploratory Data Analysis, and Model Validation. \n",
    "2. The efficacy of the federated learning platform and the similarity of performance compared to a centralzied solution.\n",
    "3. Ease of use and seamless integration of integrate's solution into any data science working environment.\n",
    "\n",
    "# **Use Case Description**\n",
    "\n",
    "An insurance company is interested in evaluating the changes in the new Peril Score released by a provider to understand whether the distribution change is disruptive to their processes and whether they should upgrade or not\n",
    "\n",
    "There are two core questions the insurance company's data scientists are interested in answering in evaluating the provider's peril score:\n",
    "\n",
    "1. **Match Rate:** How much data from the data provider's data product is usable in reference to my internal data?\n",
    "2. **Relevance:** How different and useful is the new score to their business metrics and processes\n",
    "\n",
    "This guide seeks to answer these two questions using integrate.ai's platform, and compare the methodology and the results to the scenario where all the data is centralzied and joined in one database. We will start by demonstrating how the match rate can be calculated using IAI's Private Record Linkage. We will then show how a data scientist can use integrate's solution to perform exploratory data analysis to understand the differences in the old and the new score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d5bfa-b6ba-4b57-943c-c58b29cb739a",
   "metadata": {},
   "source": [
    "# **Setup and Configuration**\n",
    "\n",
    "If you are on the full simulation PoC package, before running this notebook you should first [install the Integrate.ai components](https://documentation.integrateai.net/#hfl-data-requirements), and complete required setup and configuration for Task Runners. For details, see [Using integrate.ai](https://documentation.integrateai.net/#using-integrate-ai). The notebook is based on two AWS Task Runners simulating the training environment of a **Data Consumer** and **Insurance Carrier Company**, respectively. To set up your Task Runner on Azure refer to https://documentation.integrateai.net/#azure-configuration-for-task-runners\n",
    "For a more realistic simulation, integrate.ai will set up the partner environment for you and the provider datasets will be shared with you in your IAI workspace. \n",
    "\n",
    "If you are on a no installation PoC package, your environment needs to be fully set up by your customer success team. You can check this by looking through the datasets available to you in your IAI workspace. Contact your customer success agent to learn more.\n",
    "\n",
    "The datasets used in the PoCs are either publicly available or synthetic datasets. You must download these datasets for the centralized analyses. Here are the links to the datasets used in this notebook for this use case:\n",
    "\n",
    "LINK TO PUBLIC S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a6a6f-e031-448e-80f8-d818106eb478",
   "metadata": {},
   "source": [
    "# **Match Rate Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeed76-bb49-456b-905d-2adef053ec79",
   "metadata": {},
   "source": [
    "## **Centralzied**\n",
    "\n",
    "The centralized match rate is created by loading the two datasets into a dataframe, and performing a join and a count on the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abc4c89-3a10-4b14-ae8a-3e3d3ebe7bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "insurance_train_centralized = pd.read_csv(\"./consumer_old_peril_train.csv\")\n",
    "insurance_test_centralized = pd.read_csv(\"./consumer_old_peril_test.csv\")\n",
    "\n",
    "provider_centralized = pd.read_csv(\"./provider.csv\")\n",
    "\n",
    "overlap_train_centralized = pd.merge(insurance_train_centralized, provider_centralized, how='inner', on=['id'] )\n",
    "overlap_test_centralized = pd.merge(insurance_test_centralized, provider_centralized, how='inner', on=['id'] )\n",
    "\n",
    "matchrate_train_centralized =  overlap_train_centralized.shape[0]\n",
    "matchrate_test_centralized =  overlap_test_centralized.shape[0]\n",
    "\n",
    "\n",
    "print(matchrate_train_centralized)\n",
    "print(matchrate_test_centralized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a119b-f894-49c7-a735-49b021ccacc7",
   "metadata": {},
   "source": [
    "## **integrate.ai**\n",
    "\n",
    "integrate.ai's solution calculates the match rate by performing Private Record Linkage (PRL). Overlapping records are determined privately through a PRL session, which combines Private Set Intersection with Private Record Alignment. PRL uses the intersection to create alignment between the different collaborating datasets.\n",
    "\n",
    "PRL sessions allow the integrate.ai platform to perform match rate analysis by counting the overlapping records, conduct safe analytics by performing secure statistical analysis on the overlap, and train models on the overlap of the participating datasets without exposing the overlap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b83960-209c-467c-b8b7-53bd3c03a84a",
   "metadata": {},
   "source": [
    "### Set environment variables with your IAI credentials\n",
    "\n",
    "Generate and manage this token in your company's integrate.ai workspace UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e577eac1-8eee-4862-b281-d4638c57770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "import os\n",
    "import json\n",
    "\n",
    "IAI_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjdXN0b21lciI6ImRlbWFuZCIsImVtYWlsIjoicm9zaGFuK2RlbWFuZGRzQGludGVncmF0ZS5haSIsInJlYWxtIjoiaWZsIiwicm9sZSI6Im1vZGVsX2J1aWxkZXIiLCJlbnYiOiJwcm9kIiwidG9rZW5faWQiOiJlZjQ1ZDhhODBiZWU0OWRjYmQ5ZmMzZWY1OWYwYmNiMyIsImlzcyI6ImludGVncmF0ZS5haSIsImlhdCI6MTcxOTkzMTM2NywicmVuZXdhYmxlIjp0cnVlfQ.lPILhg42R0WUDTk4BTO18TT0CoWSNPAlw-GQPgoQgLs\"\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc4e85f-2752-40d1-ae27-a8fb5f07f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355ac13-a15c-4be7-a9df-ebbd9b99c653",
   "metadata": {},
   "source": [
    "### Set your AWS variables\n",
    "\n",
    "**Important: The task runner expects your data to be in the bucket that was created when the task runner was provisioned.**\n",
    "\n",
    "A data scientist can access the data in two ways in the following session. If the dataset is registered with the Task Runner, it can be specified in the session by the dataset name (`train_dataset_name` and `test_dataset_name`). Otherwise, the dataset path should be provided to identify the data, as in the example below.\n",
    "\n",
    "**Note, the datasets in this notebook are publicly available. The datasets can be registered with your own task runner and fully in your own control, hybrid of your taskrunner and IAI task runners to mimic a real situation, or registered fully with IAI task runners to allow you to move quickly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a975f6-3c82-4ef2-a7b7-b3d19f488dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to train and test datasets for both parties\n",
    "consumer_train_path = 'consumer_old_peril_train'\n",
    "consumer_test_path = 'consumer_old_peril_test'\n",
    "\n",
    "provider_train_path = 'provider'\n",
    "provider_test_path = 'provider'\n",
    "\n",
    "target = 'loss_amount_log'\n",
    "score_of_interest = \"total\"\n",
    "\n",
    "consumer_features = ['loss_amount', 'frequency', 'policy_type', 'renewed', 'deductible', 'Premium']\n",
    "provider_features = ['total', 'crime', 'fire', 'other', 'sewer', 'water', 'windhail']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6117c0b-3248-4a0b-b505-ef90862ed2ae",
   "metadata": {},
   "source": [
    "The task runners used for this notebook are `supplyaws` and `demandaws`. If you are on the full installation PoC package you need to replace the `demandaws` with your own taskrunner name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80794610-4c0d-41d1-b958-540e9dfe590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder.integrate_ai import IntegrateAiTaskBuilder\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder import taskrunner_context\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.integrate_ai import IntegrateAiTaskBuilder\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from typing import Iterable, Optional\n",
    "from integrate_ai_sdk.api import Client\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.taskrunner_context import TaskRunnerContext\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.taskrunner_task import ClientTask, FLSTask, ClientTaskConfig\n",
    "\n",
    "iai_tb_aws_provider = IntegrateAiTaskBuilder(client=client,\n",
    "                                         task_runner_id=\"supplyaws\")\n",
    "\n",
    "iai_tb_aws_consumer = IntegrateAiTaskBuilder(client=client,\n",
    "                                       task_runner_id=\"demandaws\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b924c7-3b31-4bb7-8e73-b76d0c4122cf",
   "metadata": {},
   "source": [
    "## Private Record Linkage (PRL)\n",
    "\n",
    "To facilitate match rate analysis, integrate.ai's Private Record Linkage feature privately joins the features of different clients using a common key - often a global index, or a combination of features that can be matched to identify an individual. Here a client means a participating party that provides dataset to the collaboration.\n",
    "\n",
    "**Join key**\n",
    "\n",
    "In this guide notebook, the synthetic data and provider data are linked by a join key (i.e. `oak`), specified as `id_columns` in the data config. For more information on how to configure an PRL session, see the documentation [here](https://documentation.integrateai.net/#prl-session-example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9adb63d8-fa3e-45fa-ab1c-7d784bad42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Specify PRL dataset configuration\n",
    "\n",
    "prl_data_config = {\n",
    "    \"clients\": {\n",
    "        \"consumer_old_peril_train\": {\n",
    "            \"id_columns\": [\"id\"],\n",
    "            \"backend\": {\"name\": \"dask\", \"n_data_partitions\": 10, \"memory_threshold\":0.4},\n",
    "        },\n",
    "        \"provider\": {\n",
    "            \"id_columns\": [\"id\"],\n",
    "            \"backend\": {\"name\": \"dask\", \"n_data_partitions\": 10, \"memory_threshold\":0.4},\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05dce4eb-6deb-4623-b2b6-8278c89b7345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b7813f320c'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Create and start PRL session\n",
    "\n",
    "prl_session = client.create_prl_session(\n",
    "    name=\"peril score - PRL\",\n",
    "    description=\"I am running PRL session with synthetic peril score data and the consumer data\",\n",
    "    data_config=prl_data_config\n",
    ").start()\n",
    "\n",
    "prl_session.id #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d35b9d-fa2e-47af-a990-1bf843bef925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a task group with one task for each client joining the session\n",
    "\n",
    "task_group = (\n",
    "    SessionTaskGroup(prl_session)\n",
    "    .add_task(iai_tb_aws_consumer.prl(train_dataset_name=consumer_train_path, test_dataset_name=consumer_test_path, client_name=\"consumer_old_peril_train\"))\\\n",
    "    .add_task(iai_tb_aws_provider.prl(train_dataset_name=provider_train_path, test_dataset_name=provider_test_path, client_name=\"provider\"))\n",
    ")\n",
    "\n",
    "task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77d35a-a48b-4e45-b657-a9027b83a9b5",
   "metadata": {},
   "source": [
    "You can use `task_group_context.contexts.values()` and `task_group_context.monitor_task_logs()` to track and see the taskrunner and orchastration logs. Equivalently, you can see the system logs in the UI under the sessions section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531d9bd-6a03-4d20-ac27-5b02fc5edfc5",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "You can find the result of the match rate analysis in the PRL session metrics or the summary table below. In these results, the client `consumer` represents the match in the consumer data. You can see how the values of overlap between train and test sets matches those of the centralized analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b5f4da7-8ee7-4f68-aa3c-ca2e35d74518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_records</th>\n",
       "      <th>n_overlapped_records</th>\n",
       "      <th>frac_overlapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_records  n_overlapped_records  frac_overlapped\n",
       "train    40000.0               40000.0              1.0\n",
       "test     10000.0               10000.0              1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = prl_session.metrics().as_dict()\n",
    "summary_table = pd.DataFrame(metrics['client_metrics']['consumer_old_peril_train']).T\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "754f98e7-6c40-4b03-a152-f72e6f4fa4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(matchrate_train_centralized)\n",
    "print(matchrate_test_centralized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003769cd-93f6-4ad6-aa37-7faab73f7dfc",
   "metadata": {},
   "source": [
    "## **Common Feature Analysis**\n",
    "In order to understand the changes in the scores\n",
    "1. We will perform exploratory analysis on top of the scores columns to understand the differences between the two features.\n",
    "2. We will perform exploratory analysis on top of the scores columns for the records that differ on their scores.\n",
    "3. We will perform model training to understand the value of the new score compared to the older version of the score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326da02b-ffa3-470c-a7d7-2337e4a236e3",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11be72f2-d88c-4c99-b45c-559d40e4b633",
   "metadata": {},
   "source": [
    "## **Centralized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3615c4b6-75d7-49c1-8fe9-7eaeb730191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire_old</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fire_old</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.981304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fire_old      fire\n",
       "fire_old  1.000000  0.981304\n",
       "fire      0.981304  1.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_train_centralized[[\"fire_old\",\"fire\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d86cbc07-1ca5-4ff4-8be0-519184b61124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_amount_log</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss_amount_log</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.305366</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loss_amount_log      fire\n",
       "loss_amount_log         1.000000  0.305366\n",
       "fire                    0.305366  1.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_train_centralized[[\"loss_amount_log\",\"fire\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b21ac-17ca-4d8e-abf3-48e8ded33038",
   "metadata": {},
   "source": [
    "## **integrateai**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "862cf677-e266-4d9e-9a2e-b31a3d0655e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_data_config = {\"consumer_old_peril_train\": [], \"provider\": []}\n",
    "paired_columns = {\"consumer_old_peril_train\":[\"fire_old\",\"loss_amount_log\"], \"provider\":[\"fire\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1cc4cd8-f743-44d3-8439-a646dd575054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa5a12b297'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_session = client.create_eda_session(\n",
    "    name=\"peril score - EDA intersect\",\n",
    "    description=\"I am running a EDA intersect session\",\n",
    "    data_config=eda_data_config,\n",
    "    eda_mode=\"intersect\",\n",
    "    paired_columns=paired_columns,\n",
    "    hide_intersection=False,\n",
    "    prl_session_id=prl_session.id\n",
    ").start()\n",
    "\n",
    "eda_session.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8ff84c5-4e9a-48ba-a59e-d9a3cd3be31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_group = (\n",
    "    SessionTaskGroup(eda_session)\n",
    "    .add_task(iai_tb_aws_consumer.eda(dataset_name=consumer_train_path, job_timeout_seconds= 10*60*60))\\\n",
    "    .add_task(iai_tb_aws_provider.eda(dataset_name=provider_train_path, job_timeout_seconds= 10*60*60))\n",
    ")\n",
    "\n",
    "task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7b23bc1-fb63-4061-8ad3-dc9f28383fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eda_session.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5ed43ce-207d-43de-91ca-a7ac2e43a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_old_peril_train@fire_old</th>\n",
       "      <th>provider@fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consumer_old_peril_train@fire_old</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provider@fire</th>\n",
       "      <td>0.780078</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   consumer_old_peril_train@fire_old  \\\n",
       "consumer_old_peril_train@fire_old                           1.000000   \n",
       "provider@fire                                               0.780078   \n",
       "\n",
       "                                   provider@fire  \n",
       "consumer_old_peril_train@fire_old       0.780078  \n",
       "provider@fire                           1.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer = results['consumer_old_peril_train']\n",
    "provider = results['provider']\n",
    "results.corr(consumer['fire_old'],provider['fire'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc9456c3-c0c3-4e2e-9de8-f0c2c1595be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_old_peril_train@loss_amount_log</th>\n",
       "      <th>provider@fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>consumer_old_peril_train@loss_amount_log</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provider@fire</th>\n",
       "      <td>0.220161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          consumer_old_peril_train@loss_amount_log  \\\n",
       "consumer_old_peril_train@loss_amount_log                                  1.000000   \n",
       "provider@fire                                                             0.220161   \n",
       "\n",
       "                                          provider@fire  \n",
       "consumer_old_peril_train@loss_amount_log       0.220161  \n",
       "provider@fire                                  1.000000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.corr(consumer['loss_amount_log'],provider['fire'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99290919-323e-44c0-9ff9-1048cef70c6c",
   "metadata": {},
   "source": [
    "## **Model Performance**\n",
    "\n",
    "We will train two models, one with only the old scores available at the carrier and the other with the new scores in the provider data. If the new score is better than the old one we should see a performance improvement on the provider score model compared to the consumer score model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "401978cc-53a0-4695-a3e6-239daf7693cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_features_base = []\n",
    "\n",
    "consumer_features_base = ['policy_type', 'renewed', 'deductible', 'Premium', 'loss_amount',\n",
    "                         'total_old_norm', 'crime_old_norm',\n",
    "       'fire_old_norm', 'other_old_norm', 'sewer_old_norm', 'water_old_norm',\n",
    "       'windhail_old_norm']\n",
    "\n",
    "\n",
    "provider_features_challenger = [ 'total_norm', 'crime_norm', 'fire_norm', 'other_norm',\n",
    "       'sewer_norm', 'water_norm', 'windhail_norm']\n",
    "consumer_features_challenger = ['policy_type', 'renewed', 'deductible', 'Premium', 'loss_amount']\n",
    "\n",
    "target = \"loss_amount_log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05ad86-26ff-4a99-bc7a-c6af1411e7c8",
   "metadata": {},
   "source": [
    "### **Centralized**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d151b14-d28b-45b2-a40c-2e6568477f89",
   "metadata": {},
   "source": [
    "#### **Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2fd34ae-de7e-4a52-8318-33d4fbd8b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base = insurance_train_centralized[consumer_features_base]\n",
    "y_train_base = insurance_train_centralized[target]\n",
    "\n",
    "X_test_base = insurance_test_centralized[consumer_features_base]\n",
    "y_test_base = insurance_test_centralized[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ee8e649-d35f-454b-92d8-e13f19cbd20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.6476921739740272e+29"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# run this part if you want to use generalized linear model as your model type\n",
    "baseline = SGDRegressor(max_iter=100, learning_rate='constant', eta0=0.0002, random_state=23)\n",
    "\n",
    "baseline.fit(X_train_base, y_train_base)\n",
    "\n",
    "# Print the number of iterations\n",
    "print('Number of iterations =', baseline.n_iter_)\n",
    "\n",
    "y_pred_base = baseline.predict(X_test_base)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_base = r2_score(y_test_base, y_pred_base)\n",
    "r2_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50508ac7-7b48-4869-bd31-75042ec1baae",
   "metadata": {},
   "source": [
    "#### **Challenger Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12b340a8-fae1-45ba-95b9-5dc3fb09f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_challenger = overlap_train_centralized[consumer_features_challenger+provider_features_challenger]\n",
    "y_train_challenger = overlap_train_centralized[target]\n",
    "\n",
    "X_test_challenger = overlap_test_centralized[consumer_features_challenger+provider_features_challenger]\n",
    "y_test_challenger = overlap_test_centralized[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "996a84b1-0a5c-48fa-a7fe-726b7f976522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.6046721847101447e+29"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenger = SGDRegressor(max_iter=100, learning_rate='constant', eta0=0.0002, random_state=23)\n",
    "\n",
    "challenger.fit(X_train_challenger, y_train_challenger)\n",
    "\n",
    "# Print the number of iterations\n",
    "print('Number of iterations =', baseline.n_iter_)\n",
    "\n",
    "y_pred_challenger = challenger.predict(X_test_challenger)\n",
    "\n",
    "\n",
    "r2_challenger = r2_score(y_test_challenger, y_pred_challenger)\n",
    "r2_challenger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7844eb4-1492-4bdd-8fc2-fd4ac6828a2f",
   "metadata": {},
   "source": [
    "### **integrateai**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413a50f-e2a0-4050-9394-640a83ef4e30",
   "metadata": {},
   "source": [
    "#### **Challenger Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f960193-bfe1-4f13-9e5c-428a294df8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "     \"strategy\": {\"name\": \"VflGlm\", \"params\": {}},\n",
    "     \"model\": {\n",
    "         \"provider\": {\"params\": {\"input_size\": len(provider_features_challenger), \"output_activation\": None}},\n",
    "         \"consumer_old_peril_train\": {\"params\": {\"input_size\": len(consumer_features_challenger), \"output_activation\": None}},\n",
    "     },\n",
    "     \"ml_task\": {\n",
    "         \"type\": \"normal\",\n",
    "         \"params\": {},\n",
    "     },\n",
    "     \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.1, \"momentum\": 0.0}},\n",
    "     \"feature_importance_score\": {\"enable\": True, \"params\": {\"max_evals\": 200, \"subsample\":0.5, \"random_seed\": 23}},\n",
    "     \"seed\": 23,  # for reproducibility\n",
    " }\n",
    "data_config = {\n",
    "        \"provider\": {\n",
    "            \"label_client\": False,\n",
    "            \"predictors\": provider_features_challenger,\n",
    "            \"target\": None,\n",
    "        },\n",
    "        \"consumer_old_peril_train\": {\n",
    "            \"label_client\": True,\n",
    "            \"predictors\": consumer_features_challenger,\n",
    "            \"target\": target,\n",
    "        },\n",
    "    }\n",
    "\n",
    "consumer_storage_path = 's3://demand-demandaws.integrate.ai/model'\n",
    "provider_storage_path = 's3://supply-supplyaws.integrate.ai/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0643bcc0-97b9-41c9-a99b-e4ecc910d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_train_session = client.create_vfl_session(\n",
    "    name=\"peril score - VFL model Train\",\n",
    "    description=\"I am train a federated model with peril score and the consumer data\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    vfl_mode='train',\n",
    "    min_num_clients=2,\n",
    "    num_rounds=20,\n",
    "    package_name=\"iai_glm\", \n",
    "    data_config=data_config,\n",
    "    model_config=model_config\n",
    ").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e32b06b4-ed23-427b-aae0-807eef182e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfl_task_group_context = (SessionTaskGroup(fl_train_session)\\\n",
    "    .add_task(iai_tb_aws_consumer.vfl_train(train_dataset_name=consumer_train_path,\n",
    "                                    test_dataset_name=consumer_test_path,\n",
    "                                    client_name=\"consumer_old_peril_train\",\n",
    "                                    batch_size=4096,\n",
    "                                    storage_path=consumer_storage_path,\n",
    "                                    memory= str(32 * 1024),\n",
    "                                    job_timeout_seconds= 10*60*60))\\\n",
    "    .add_task(iai_tb_aws_provider.vfl_train(train_dataset_name=provider_train_path,\n",
    "                                    test_dataset_name=provider_test_path,\n",
    "                                    client_name=\"provider\",\n",
    "                                    batch_size=4096,\n",
    "                                    storage_path=provider_storage_path,\n",
    "                                    memory= str(32 * 1024),\n",
    "                                    job_timeout_seconds= 10*60*60))\\\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2d544-43d7-45bf-b5ff-659743f41509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_metrics = fl_train_session.metrics()\n",
    "r2_fed = list(fl_metrics.client_metrics[-1].values())[0][\"test_r2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ac9d6-73f9-4f04-a7dd-9380c1808455",
   "metadata": {},
   "source": [
    "## **Conclusions**\n",
    "Here is the comparison between the $R2$ score of the differnt models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9cf06-4be4-4bdd-b2d8-5be0c29a50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(baseline_model_centralized=r2_base, challenger_model_centralized=r2_challenger, challenger_model_federated=r2_fed)\n",
    "results_df = pd.DataFrame(results,index=[0])\n",
    "results_df.plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
